{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1M8atARCCSpDsUuHAQRs5MxTv5fkeR5rX",
      "authorship_tag": "ABX9TyMTJcGpFK19mr9rVxuiV2u0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_H%26M_EDA_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_ia2TrXDB2",
        "outputId": "3bb18f3a-93d7-407f-bcd4-c7730950ba3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/odins0n/hm256x256\n",
            "License(s): other\n",
            "Downloading hm256x256.zip to /content\n",
            " 99% 2.10G/2.13G [00:27<00:00, 56.5MB/s]\n",
            "100% 2.13G/2.13G [00:27<00:00, 83.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Install Kaggle modules and download the dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
        "!kaggle datasets download -d odins0n/hm256x256\n",
        "!unzip -q \"/content/hm256x256.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3eac20"
      },
      "source": [
        "## Let's Explore the H&M Fashion World Together!\n",
        "\n",
        "Get ready to explore the amazing H&M Personalized Fashion Recommendations dataset! This is a fun challenge from Kaggle. Our main goal? To build a cool system that suggests clothes people will love, based on what they've bought before. But first, we need to get to know our data!\n",
        "\n",
        "**Why explore this dataset? It's like going on a treasure hunt!**\n",
        "\n",
        "Exploring our data is super important. It helps us:\n",
        "\n",
        "*   **See what we have:** Look at all the different pieces of information about customers, clothes, and sales.\n",
        "*   **Spot any messy bits:** Find things that might be missing or don't look quite right.\n",
        "*   **Find cool patterns:** Discover interesting trends in what people buy and when.\n",
        "*   **Get ideas for our model:** Think of clever ways to use the data to make great recommendations.\n",
        "*   **Choose the best tools:** Figure out which methods will work best for our recommendation system.\n",
        "\n",
        "**How will we explore? It's easy and fun!**\n",
        "\n",
        "We'll use simple steps to explore:\n",
        "\n",
        "*   We'll load everything up so we can see it clearly.\n",
        "*   We'll look at numbers and pictures to understand things like customer ages and how much clothes cost.\n",
        "*   We'll see how different pieces of information fit together.\n",
        "*   We'll check for any missing puzzle pieces.\n",
        "\n",
        "**What's the big goal of exploring? To become data detectives!**\n",
        "\n",
        "By exploring, we want to:\n",
        "\n",
        "*   Really understand the H&M fashion world in our data.\n",
        "*   Learn all about the customers, the clothes, and the sales.\n",
        "*   Find exciting clues that will help us build an awesome recommendation system.\n",
        "*   Get everything ready for the next steps, like preparing the data and building our model.\n",
        "\n",
        "Let's have fun exploring and build something amazing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ed17f54"
      },
      "source": [
        "# Firstly first\n",
        "Let's start by loading all the necessary libraries and the datasets we'll be working with: `articles.csv`, `customers.csv`, and `transactions_train.csv`. This will prepare our environment and make the data available for exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "976cbd00"
      },
      "source": [
        "#Load all libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "import plotly.graph_objects as go\n",
        "import datetime as dt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "#Load all the datasets\n",
        "articles = pd.read_csv(\"/content/articles.csv\")\n",
        "customers = pd.read_csv(\"/content/customers.csv\")\n",
        "transactions = pd.read_csv(\"/content/transactions_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}