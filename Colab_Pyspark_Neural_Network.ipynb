{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQUj6TaCOPmur2cInTR+Pk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnyBfPJnJlXS",
        "outputId": "2a07f464-1cac-45b7-8c71-a87ed8f92ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Downloading digit-recognizer.zip to /content\n",
            "  0% 0.00/15.3M [00:00<?, ?B/s]\n",
            "100% 15.3M/15.3M [00:00<00:00, 433MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Install Kaggle modules and download the dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
        "!kaggle competitions download -c digit-recognizer\n",
        "!unzip -q \"/content/digit-recognizer.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# 1. Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MNIST_Neural_Network\").getOrCreate()\n",
        "\n",
        "# 2. Load training data\n",
        "train_df = spark.read.csv(\"/content/train.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# 3. Assemble features\n",
        "pixel_cols = [f\"pixel{i}\" for i in range(784)]\n",
        "assembler = VectorAssembler(inputCols=pixel_cols, outputCol=\"features_raw\")\n",
        "train_df = assembler.transform(train_df)\n",
        "\n",
        "# 4. Normalize features (0â€“1)\n",
        "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "scaler_model = scaler.fit(train_df)\n",
        "scaled_train_df = scaler_model.transform(train_df).select(\"label\", \"features\")\n",
        "\n",
        "# 5. Train-test split\n",
        "train_data, test_data = scaled_train_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 6. Define neural network layers\n",
        "layers = [784, 128, 64, 10]  # input â†’ hidden1 â†’ hidden2 â†’ output (10 classes)\n",
        "\n",
        "# 7. Train neural network model\n",
        "mlp = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=100, layers=layers, blockSize=128, seed=123)\n",
        "mlp_model = mlp.fit(train_data)\n",
        "\n",
        "# 8. Evaluate accuracy\n",
        "predictions = mlp_model.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"âœ… Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 9. Confusion matrix\n",
        "pred_rdd = predictions.select(\"prediction\", \"label\").rdd.map(lambda row: (float(row[0]), float(row[1])))\n",
        "metrics = MulticlassMetrics(pred_rdd)\n",
        "print(\"\\nðŸ“Š Confusion Matrix:\")\n",
        "print(metrics.confusionMatrix().toArray())\n",
        "\n",
        "# 10. Save the model\n",
        "mlp_model.write().overwrite().save(\"mlp_mnist_model\")\n",
        "print(\"ðŸ’¾ Model saved as: mlp_mnist_model\")\n",
        "\n",
        "# 11. Load test data\n",
        "test_df = spark.read.csv(\"/content/test.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# 12. Assemble and scale test features\n",
        "test_df = assembler.transform(test_df)\n",
        "test_scaled = scaler_model.transform(test_df).select(\"features\")\n",
        "\n",
        "# 13. Load model and predict test labels\n",
        "loaded_model = MultilayerPerceptronClassificationModel.load(\"mlp_mnist_model\")\n",
        "test_predictions = loaded_model.transform(test_scaled).select(\"prediction\")\n",
        "\n",
        "# 14. Add ImageId for submission\n",
        "test_predictions = test_predictions.withColumn(\"ImageId\", (col(\"prediction\").rdd.zipWithIndex().map(lambda x: x[1] + 1)).toDF(\"ImageId\"))\n",
        "submission = test_predictions.selectExpr(\"ImageId\", \"int(prediction) as Label\")\n",
        "\n",
        "# 15. Export submission file\n",
        "submission.coalesce(1).write.csv(\"submission\", header=True, mode=\"overwrite\")\n",
        "print(\"ðŸ“¤ Submission saved to ./submission/\")\n"
      ],
      "metadata": {
        "id": "5LjrFsHYLxxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}