{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNNBK13GuPhWMpb5G10wWE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KnnR7M67p78",
        "outputId": "6a82067e-507c-4a22-a439-989682fcc26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Downloading predict-student-performance-from-game-play.zip to /content\n",
            " 99% 960M/968M [00:11<00:00, 117MB/s] \n",
            "100% 968M/968M [00:11<00:00, 89.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Install Kaggle modules and download the dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
        "!kaggle competitions download -c predict-student-performance-from-game-play\n",
        "!unzip -q \"/content/predict-student-performance-from-game-play.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, split, struct\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "dMLcwRWF7yh2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
        "\n",
        "# Define schema for train.csv\n",
        "train_schema = StructType([\n",
        "    StructField(\"session_id\", LongType(), True),\n",
        "    StructField(\"index\", ShortType(), True),\n",
        "    StructField(\"elapsed_time\", IntegerType(), True),\n",
        "    StructField(\"event_name\", StringType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"level\", ByteType(), True),\n",
        "    StructField(\"page\", IntegerType(), True),\n",
        "    StructField(\"room_coor_x\", DoubleType(), True),\n",
        "    StructField(\"room_coor_y\", DoubleType(), True),\n",
        "    StructField(\"screen_coor_x\", DoubleType(), True),\n",
        "    StructField(\"screen_coor_y\", DoubleType(), True),\n",
        "    StructField(\"hover_duration\", DoubleType(), True),\n",
        "    StructField(\"text\", StringType(), True),\n",
        "    StructField(\"fqid\", StringType(), True),\n",
        "    StructField(\"room_fqid\", StringType(), True),\n",
        "    StructField(\"text_fqid\", StringType(), True),\n",
        "    StructField(\"fullscreen\", ByteType(), True),\n",
        "    StructField(\"hq\", ByteType(), True),\n",
        "    StructField(\"music\", ByteType(), True),\n",
        "    StructField(\"level_group\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Load train.csv\n",
        "df_train = spark.read.format(\"csv\").option(\"header\", True).schema(train_schema).load(\"/content/train.csv\")\n",
        "print ('**** output: df_train ****')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCfGjtOT8Tar",
        "outputId": "a65eb57f-2af5-49a8-b5bf-21748c3385fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** output: df_train ****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_transformation(df):\n",
        "    # Select the numeric columns of the dataframe, excluding \"page\"\n",
        "    numeric_cols = [c for c, dtype in df.dtypes if dtype == 'double' and c != 'page']\n",
        "\n",
        "    # Calculate the mean of the values in each numeric column, except \"page\"\n",
        "    means = df.agg(*(mean(c).alias(c) for c in numeric_cols)).first().asDict()\n",
        "\n",
        "    # Define the fill value for the \"page\" column as zero\n",
        "    fill_values = means\n",
        "    fill_values['page'] = 0\n",
        "\n",
        "    # Fill missing values with fill values\n",
        "    filled = df.fillna(fill_values)\n",
        "\n",
        "    # Fill missing data in hover_duration column with 0\n",
        "    filled = filled.fillna(0, subset=['hover_duration'])\n",
        "\n",
        "    # Drop rows with missing values in \"level_group\" column\n",
        "    filled = filled.na.drop(subset=[\"level_group\"])\n",
        "\n",
        "    # Check categorical columns and fill with 0\n",
        "    categorical_cols = [c for c, dtype in df.dtypes if dtype == 'string']\n",
        "    filled = filled.fillna('0', subset=categorical_cols)\n",
        "\n",
        "    # Transform categorical data into numerical data using StringIndexer\n",
        "    indexer = StringIndexer(inputCols=['event_name', 'name', 'fqid', 'text', 'room_fqid', 'text_fqid'],\n",
        "                            outputCols=['event_name_idx', 'name_idx', 'fqid_idx', 'text_idx', 'room_fqid_idx', 'text_fqid_idx'])\n",
        "    indexed = indexer.fit(filled).transform(filled)\n",
        "\n",
        "    categorical_cols = [c for c, dtype in indexed.dtypes if dtype == 'string' and c != 'level_group']\n",
        "    all_cols = indexed.columns\n",
        "    numeric_cols = [col_name for col_name in all_cols if col_name not in categorical_cols]\n",
        "    df_numeric = indexed.select(numeric_cols)\n",
        "\n",
        "    # Group the data by the specified column combination and calculate the mean of the remaining numeric columns\n",
        "    cols_for_group = ['elapsed_time', 'page', 'room_coor_x', 'room_coor_y', 'screen_coor_x',\n",
        "                      'screen_coor_y', 'hover_duration', 'fullscreen', 'hq', 'music','event_name_idx', 'name_idx',\n",
        "                      'fqid_idx', 'text_idx', 'room_fqid_idx', 'text_fqid_idx']\n",
        "    grouped = df_numeric.groupby(['session_id', 'level_group']).agg(*(avg(col(c)).alias(c) for c in cols_for_group))\n",
        "\n",
        "    # Define a mapping of old column names to new ones\n",
        "    column_mapping = {\n",
        "        'event_name_idx': 'event_name',\n",
        "        'name_idx': 'name',\n",
        "        'text_idx': 'text',\n",
        "        'fqid_idx': 'fqid',\n",
        "        'room_fqid_idx': 'room_fqid',\n",
        "        'text_fqid_idx': 'text_fqid',\n",
        "        'fullscreen': 'fullscreen',\n",
        "    }\n",
        "\n",
        "    # Rename columns using the mapping defined above\n",
        "    grouped = grouped.toDF(*[column_mapping.get(col, col) for col in grouped.columns])\n",
        "\n",
        "    # Transform pyspark dataframe to pandas datraframe\n",
        "    df_pandas = grouped.toPandas()\n",
        "    print('************** Done!!! ***************')\n",
        "\n",
        "    return df_pandas\n",
        "\n",
        "dftrain = data_transformation(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr-ktmjr84_V",
        "outputId": "bbcc9018-2f53-4d95-dcb9-9f63f539b93a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************** Done!!! ***************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "def data_transformation_test(df):\n",
        "    # Seleciona as colunas numéricas do dataframe, excluindo \"page\"\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    numeric_cols = numeric_cols[2:]\n",
        "    numeric_cols.remove('page')\n",
        "\n",
        "\n",
        "    # Preenche os valores faltantes com a média\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    # Preenche os valores faltantes em hover_duration com 0\n",
        "    df['hover_duration'] = df['hover_duration'].fillna(0)\n",
        "    df['page'] = df['page'].fillna(0)\n",
        "\n",
        "    # Seleciona as colunas categóricas do dataframe\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Preenche os valores faltantes em cada coluna categórica com \"0\"\n",
        "    df[categorical_cols] = df[categorical_cols].fillna('0')\n",
        "\n",
        "    # Transforma dados categóricos em dados numéricos usando LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    df = df.drop(columns=['index'])\n",
        "    #df = df.set_index('session_id')\n",
        "\n",
        "    \"\"\"\n",
        "    Cria uma nova coluna \"level_group\" com base na coluna \"question\" do DataFrame df.\n",
        "    \"\"\"\n",
        "    # Define as condições para a criação da nova coluna \"level_group\"\n",
        "    conditions = [\n",
        "        (df[\"level_group\"] == 0),\n",
        "        (df[\"level_group\"] == 1),\n",
        "        (df[\"level_group\"] == 2)\n",
        "    ]\n",
        "\n",
        "    # Define os valores a serem atribuídos à nova coluna \"level_group\" de acordo com as condições\n",
        "    values = [\"0-4\", \"5-12\", \"13-22\"]\n",
        "\n",
        "    # Cria a nova coluna \"level_group\" with correct data type\n",
        "    df[\"level_group\"] = np.select(conditions, values, default=df[\"level_group\"])\n",
        "\n",
        "#     # Criar um dicionário que mapeia os valores de \"level_group\" para seus respectivos valores numéricos\n",
        "#     level_group_dict = {'0-4': 0, '5-12': 1, '13-22': 2}\n",
        "#     df['level_group'] = df['level_group'].apply(lambda x: level_group_dict.get(x, 0))\n",
        "\n",
        "    return df\n",
        "\n",
        "df_test  = pd.read_csv(\"/content/test.csv\")\n",
        "test_df = data_transformation_test(df_test)\n",
        "print ('******* output: test_df ********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGQfGY149IFw",
        "outputId": "ef7b4938-e2eb-48f5-a2ca-6f643d217566"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******* output: test_df ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define schema for train_labels.csv\n",
        "train_labels_schema = {\"session_id\": str, \"target\": int}\n",
        "\n",
        "#Load train_labels.csv into a Pandas DataFrame\n",
        "df_train_labels = pd.read_csv(\"/content/train_labels.csv\", dtype=train_labels_schema)\n",
        "\n",
        "#Extract session and question from session_id\n",
        "df_train_labels[[\"session_id\", \"level\"]] = df_train_labels[\"session_id\"].str.split(\"_\", expand=True)\n",
        "df_train_labels[\"session_id\"] = df_train_labels[\"session_id\"].str.extract('(\\d+)').astype(int)\n",
        "df_train_labels[\"level\"] = df_train_labels[\"level\"].str.extract('(\\d+)').astype(int)"
      ],
      "metadata": {
        "id": "2nBmX33e_k0x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_level_group_column(df):\n",
        "    \"\"\"\n",
        "    Cria a nova coluna \"level_group\" com base na coluna \"level\" do DataFrame df.\n",
        "    \"\"\"\n",
        "    # Define as condições para a criação da nova coluna \"level_group\"\n",
        "    conditions = [\n",
        "        (df[\"level\"] <= 3),\n",
        "        (df[\"level\"] <= 13),\n",
        "        (df[\"level\"] <= 22)\n",
        "    ]\n",
        "\n",
        "    # Define os valores a serem atribuídos à nova coluna \"level_group\" de acordo com as condições\n",
        "    values = [\"0-4\", \"5-12\", \"13-22\"]\n",
        "\n",
        "    # Cria a nova coluna \"level_group\"\n",
        "    df[\"level_group\"] = np.select(conditions, values, default='Unknown')\n",
        "    # Criar um dicionário que mapeia os valores de \"level_group\" para seus respectivos valores numéricos\n",
        "    level_group_dict = {'0-4': 1, '5-12': 2, '13-22': 3}\n",
        "    df['session_level'] = df['level_group'].apply(lambda x: level_group_dict.get(x, 0))\n",
        "\n",
        "    # Retorna o DataFrame com a nova coluna \"level_group\"\n",
        "    return df\n",
        "# Cria a nova coluna \"level_group\"\n",
        "target = create_level_group_column(df_train_labels)\n",
        "print ('******* output: target ********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMHEiTg-_v8l",
        "outputId": "b5a3f084-c400-4f6a-9eab-a4c6e195a067"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******* output: target ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ccab89e",
        "outputId": "f2a0bec2-c5c0-42f5-9980-4597d624e1a1"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "f1_scores = []  # List to store individual F1-scores\n",
        "\n",
        "# Define the feature columns and target column\n",
        "FEATURES = [c for c in df_train.columns if c not in [\"level_group\", \"correct\"]]\n",
        "target_column = \"correct\"\n",
        "\n",
        "# Iterate over questions from 1 to 18\n",
        "for i in range(1, 19):\n",
        "    print(f'Question {i}:')\n",
        "    target_column = 'correct'\n",
        "\n",
        "    # Select the dataset for the current question\n",
        "    current_question = df_train[df_train['level'] == i]\n",
        "\n",
        "    # Split the dataset into training and testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(current_question[FEATURES],\n",
        "                                                        current_question[target_column],\n",
        "                                                        test_size=0.3,\n",
        "                                                        random_state=42)\n",
        "\n",
        "    # Impute missing values in X_train and X_test\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Create and train the SVM model with desired parameters\n",
        "    model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the F1-score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    f1_scores.append(f1)  # Store the F1-score\n",
        "\n",
        "    print(f'F1-score: {f1}')\n",
        "\n",
        "# Calculate the average F1-score\n",
        "average_f1 = np.mean(f1_scores)\n",
        "print(f'Average F1-score: {average_f1}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "F1-score: 0.8450290008986194\n",
            "Question 2:\n",
            "F1-score: 0.989493245657923\n",
            "Question 3:\n",
            "F1-score: 0.9659913698529949\n",
            "Question 4:\n",
            "F1-score: 0.8888714240804778\n",
            "Question 5:\n",
            "F1-score: 0.7011483693155719\n",
            "Question 6:\n",
            "F1-score: 0.8773127928214087\n",
            "Question 7:\n",
            "F1-score: 0.8498210218027986\n",
            "Question 8:\n",
            "F1-score: 0.7605856053300605\n",
            "Question 9:\n",
            "F1-score: 0.8436119744806151\n",
            "Question 10:\n",
            "F1-score: 0.6620611337181792\n",
            "Question 11:\n",
            "F1-score: 0.7839325649406502\n",
            "Question 12:\n",
            "F1-score: 0.926418103120966\n",
            "Question 13:\n",
            "F1-score: 0.0\n",
            "Question 14:\n",
            "F1-score: 0.8289571771722024\n",
            "Question 15:\n",
            "F1-score: 0.0\n",
            "Question 16:\n",
            "F1-score: 0.8475709162047603\n",
            "Question 17:\n",
            "F1-score: 0.8124317513649727\n",
            "Question 18:\n",
            "F1-score: 0.9764714399478752\n",
            "Average F1-score: 0.7533171050394487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the SVM model\n",
        "clf = model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_scores = clf.decision_function(X_test)\n",
        "\n",
        "# Find the best threshold\n",
        "best_threshold = None\n",
        "best_f1_score = 0.0\n",
        "\n",
        "for threshold in np.arange(-1.0, 1.1, 0.1):\n",
        "    y_pred = (y_pred_scores > threshold).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1-score:\", best_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHJCOKTZAiCT",
        "outputId": "0f3d7e3a-5db1-41de-cb85-4b74affe1120"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: -1.0\n",
            "Best F1-score: 0.9764714399478752\n"
          ]
        }
      ]
    }
  ]
}