{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM4C6T2A3FBhqZSphrI24w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_H%26M_EDA_Recommendation_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQe5CRCR7GG",
        "outputId": "eacfe5db-0966-4a73-a897-fc86a27b5ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/odins0n/hm256x256\n",
            "License(s): other\n",
            "Downloading hm256x256.zip to /content\n",
            " 96% 2.05G/2.13G [00:12<00:02, 36.4MB/s]\n",
            "100% 2.13G/2.13G [00:12<00:00, 182MB/s] \n"
          ]
        }
      ],
      "source": [
        "#@title Install Kaggle modules and download the dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
        "!kaggle datasets download -d odins0n/hm256x256\n",
        "!unzip -q \"/content/hm256x256.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ql-SBs27TI3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7646018"
      },
      "source": [
        "âœ¨ **Getting Started** âœ¨\n",
        "\n",
        "Before we dive into building our recommendation system, we need to set up our environment. This involves installing the necessary libraries and downloading the dataset we'll be working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4669dfce",
        "outputId": "d4c98c3f-da98-4ccf-9774-3541c68a16e8"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8282150d"
      },
      "source": [
        "âš™ï¸ **Setting up Spark** âš™ï¸\n",
        "\n",
        "Before we can use PySpark, we need to start a Spark session. We'll also import some useful libraries that will help us work with data and build our recommendation model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
        "from pyspark.sql.functions import col,array_contains\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import udf,col,when\n",
        "from pyspark.sql.functions import to_timestamp,date_format\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import *\n",
        "\n",
        "sc = SparkSession.builder.appName(\"Recommendations\").config(\"spark.sql.files.maxPartitionBytes\", 5000000).getOrCreate()\n",
        "spark = SparkSession(sc)"
      ],
      "metadata": {
        "id": "lUuDA2AYTg9X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62a1c74"
      },
      "source": [
        "ðŸ’¾ **Loading the Transaction Data** ðŸ’¾\n",
        "\n",
        "We'll load the transaction data into a Spark DataFrame. This dataset contains all the purchase information, which is super important for our recommendation system."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transaction = spark.read.option(\"header\",True) \\\n",
        "              .csv(\"/content/transactions_train.csv\")\n",
        "transaction.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g00yZvVnTuIS",
        "outputId": "a26a0122-08b9-41f2-c212-4eb253dd22c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- t_dat: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- article_id: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            " |-- sales_channel_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d1ccef8"
      },
      "source": [
        "ðŸ“… **Checking the Date Range** ðŸ“…\n",
        "\n",
        "It's always good to know the time period our data covers. Let's find the earliest and latest transaction dates in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "from pyspark.sql.functions import unix_timestamp, lit\n",
        "min_date, max_date = transaction.select(min(\"t_dat\"), max(\"t_dat\")).first()\n",
        "min_date, max_date"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYUlKdr-T9To",
        "outputId": "1f97a9a4-46db-449f-e027-5582424b7060"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2018-09-20', '2020-09-22')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min as min_, max as max_\n",
        "\n",
        "# Cache the DataFrame if reused multiple times\n",
        "transaction.cache()\n",
        "\n",
        "# Aggregate min and max in one pass\n",
        "date_range = transaction.agg(\n",
        "    min_(\"t_dat\").alias(\"min_date\"),\n",
        "    max_(\"t_dat\").alias(\"max_date\")\n",
        ").collect()[0]\n",
        "\n",
        "min_date = date_range['min_date']\n",
        "max_date = date_range['max_date']\n",
        "print(min_date, max_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vLkkVSgUi4K",
        "outputId": "87a0ccc6-38dd-4e9f-cc6d-882239bb35f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-09-20 2020-09-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ea85cb8"
      },
      "source": [
        "ðŸ§¹ **Preparing the Data** ðŸ§¹\n",
        "\n",
        "We'll clean and transform the transaction data to get it ready for our recommendation system. This includes filtering by date and counting how many times each customer bought a specific article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a527e48b",
        "outputId": "574555f5-5049-4c01-f099-b050e9d1f516"
      },
      "source": [
        "hm =  transaction.withColumn('t_dat', transaction['t_dat'].cast('string'))\n",
        "hm = hm.withColumn('date', from_unixtime(unix_timestamp('t_dat', 'yyyy-MM-dd')))\n",
        "hm = hm.withColumn('year', year(col('date')))\n",
        "hm = hm.withColumn('month', month(col('date')))\n",
        "hm = hm.withColumn('day', date_format(col('date'), \"d\"))\n",
        "\n",
        "hm = hm[hm['year'] == 2020]\n",
        "hm = hm[hm['month'] == 9]\n",
        "hm = hm[hm['day'] == 22]\n",
        "transaction.unpersist()\n",
        "\n",
        "# Prepare the dataset\n",
        "hm = hm.groupby('customer_id', 'article_id').count()\n",
        "hm.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-----+\n",
            "|         customer_id|article_id|count|\n",
            "+--------------------+----------+-----+\n",
            "|00f7bc5c0df4c615b...|0780418013|    1|\n",
            "|02094817e46f3b692...|0791587001|    1|\n",
            "|0333e5dda0257e9f4...|0839332002|    2|\n",
            "|07c7a1172caf8fb97...|0573085043|    1|\n",
            "|081373184e601470c...|0714790020|    1|\n",
            "+--------------------+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((hm.count(), len(hm.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpHhtE9ii68h",
        "outputId": "5afa216e-5bf0-44a5-aa37-312c8722f461"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29486, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c24da4cc"
      },
      "source": [
        "ðŸ” **Checking Data Sparsity** ðŸ”\n",
        "\n",
        "Sparsity is a fancy word that tells us how \"empty\" our data is. In our case, it's about how many possible customer-article purchases didn't actually happen. Knowing this helps us understand our data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2c60f4a",
        "outputId": "9e15a349-bbf8-4d76-b80b-3402460d2988"
      },
      "source": [
        "# Count the total number of article in the dataset\n",
        "numerator = hm.select(\"count\").count()\n",
        "\n",
        "# Count the number of distinct customerid and distinct articleid\n",
        "num_users = hm.select(\"customer_id\").distinct().count()\n",
        "num_articles = hm.select(\"article_id\").distinct().count()\n",
        "\n",
        "# Set the denominator equal to the number of customer multiplied by the number of articles\n",
        "denominator = num_users * num_articles\n",
        "\n",
        "# Divide the numerator by the denominator\n",
        "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
        "print(\"Sparsity: \", \"%.2f\" % sparsity + \"%.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity:  99.96%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c43bd449"
      },
      "source": [
        "ðŸ“Š **Analyzing Customer Activity** ðŸ“Š\n",
        "\n",
        "It's interesting to see how often our customers make purchases. Let's count the number of transactions for each customer and see which customers are the most active."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bc06790",
        "outputId": "7e56b99a-df2b-4570-f10f-f4606d73ac1b"
      },
      "source": [
        "userId_count = hm.groupBy(\"customer_id\").count().orderBy('count', ascending=False)\n",
        "userId_count.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|         customer_id|count|\n",
            "+--------------------+-----+\n",
            "|30b6056bacc5f5c9d...|   28|\n",
            "|5e8fb4d457fdffc61...|   28|\n",
            "|dc1b173e541f8d3c1...|   27|\n",
            "|6335d496ef463bc40...|   25|\n",
            "|1796e87fd2e88932b...|   25|\n",
            "|f50287d9cf052d4b4...|   24|\n",
            "|54e8ebd39543b5a4d...|   23|\n",
            "|fd5ce8716faf00f6a...|   23|\n",
            "|850ec77661a417d27...|   22|\n",
            "|32f3a6a7ce63d302c...|   21|\n",
            "|fc783381f1ea2174c...|   21|\n",
            "|ad3663a848dccbdda...|   21|\n",
            "|b606fe5786c00151a...|   21|\n",
            "|298523b6637340717...|   21|\n",
            "|a08e284bb18add2d7...|   21|\n",
            "|383e1b07e2c1fe169...|   21|\n",
            "|b49647f84a99ced53...|   21|\n",
            "|3ca77aab50ae4532b...|   20|\n",
            "|2a721767cd9864ed5...|   20|\n",
            "|af5166e0f89b0d433...|   19|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22e1866e"
      },
      "source": [
        "ðŸ‘š **Analyzing Article Popularity** ðŸ‘–\n",
        "\n",
        "Let's see which articles are flying off the shelves! We'll count how many times each article has been purchased to find the most popular items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e4e9473",
        "outputId": "3e48a027-985e-44bd-a646-0fdba7769a53"
      },
      "source": [
        "articleId_count = hm.groupBy(\"article_id\").count().orderBy('count', ascending=False)\n",
        "articleId_count.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|article_id|count|\n",
            "+----------+-----+\n",
            "|0924243002|   91|\n",
            "|0918522001|   88|\n",
            "|0866731001|   78|\n",
            "|0751471001|   75|\n",
            "|0448509014|   73|\n",
            "|0714790020|   72|\n",
            "|0762846027|   68|\n",
            "|0928206001|   67|\n",
            "|0893432002|   66|\n",
            "|0918292001|   65|\n",
            "|0915529005|   64|\n",
            "|0788575004|   63|\n",
            "|0915529003|   63|\n",
            "|0863583001|   60|\n",
            "|0930380001|   59|\n",
            "|0573085028|   59|\n",
            "|0919273002|   58|\n",
            "|0850917001|   57|\n",
            "|0573085042|   56|\n",
            "|0874110016|   53|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee6d76db"
      },
      "source": [
        "ðŸ“‡ **Indexing Customer and Article IDs** ðŸ“‡\n",
        "\n",
        "Before we can train our recommendation model, we need to convert the customer and article IDs into numerical indexes. This helps the model work efficiently. We'll use a `StringIndexer` for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90e970e5",
        "outputId": "50f02c24-9717-4a71-cc2e-e6da33bb4353"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(hm.columns)-set(['count'])) ]\n",
        "pipeline = Pipeline(stages=indexer)\n",
        "transformed = pipeline.fit(hm).transform(hm)\n",
        "transformed.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-----+-----------------+----------------+\n",
            "|         customer_id|article_id|count|customer_id_index|article_id_index|\n",
            "+--------------------+----------+-----+-----------------+----------------+\n",
            "|00f7bc5c0df4c615b...|0780418013|    1|            783.0|          2237.0|\n",
            "|02094817e46f3b692...|0791587001|    1|            785.0|            35.0|\n",
            "|0333e5dda0257e9f4...|0839332002|    2|           4098.0|           732.0|\n",
            "|07c7a1172caf8fb97...|0573085043|    1|           1702.0|            44.0|\n",
            "|081373184e601470c...|0714790020|    1|           4146.0|             5.0|\n",
            "|09bec2a61046ccbea...|0860336002|    1|           6792.0|          2368.0|\n",
            "|0be4f1ecce204ee32...|0573085028|    1|            799.0|            14.0|\n",
            "|0c4b30343292b5101...|0918522001|    1|           6825.0|             1.0|\n",
            "|0e10e02358875468b...|0579541001|    1|           2689.0|            53.0|\n",
            "|0fc371e67e61a31d7...|0907170001|    1|           1737.0|          1978.0|\n",
            "|10817b19177f6a53e...|0718278019|    1|            805.0|           419.0|\n",
            "|10ac90988da6052dd...|0934212003|    1|            806.0|          2058.0|\n",
            "|14a298482fa7f9d52...|0894353002|    1|             87.0|          3772.0|\n",
            "|14f4b1b17991c32d2...|0803685001|    1|           1184.0|           725.0|\n",
            "|1601fa3c3f39aa623...|0730683001|    1|           4284.0|          2994.0|\n",
            "|164e1a251f0e3d764...|0831267001|    1|           4287.0|          5979.0|\n",
            "|165d2c0b0128d5619...|0909081004|    1|             88.0|          1293.0|\n",
            "|166546028742fe655...|0767423013|    1|            814.0|           974.0|\n",
            "|189b7275c513a84c8...|0877711001|    1|            204.0|          6890.0|\n",
            "|1918933afff08e955...|0914672001|    1|            285.0|          7685.0|\n",
            "+--------------------+----------+-----+-----------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}