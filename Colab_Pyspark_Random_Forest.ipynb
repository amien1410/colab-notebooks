{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNacPlULXqVW9WsBygmHPi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDDF7jjXqF0f",
        "outputId": "591d4b9f-d924-46e8-f3e4-958abb56204b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-27 13:51:47--  https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: â€˜bank+marketing.zipâ€™\n",
            "\n",
            "bank+marketing.zip      [  <=>               ] 999.85K  2.52MB/s    in 0.4s    \n",
            "\n",
            "2025-06-27 13:51:47 (2.52 MB/s) - â€˜bank+marketing.zipâ€™ saved [1023843]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Download the dataset\n",
        "!wget https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n",
        "!unzip -q \"/content/bank+marketing.zip\"\n",
        "!unzip -q \"/content/bank.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# 1. Start Spark session\n",
        "spark = SparkSession.builder.appName(\"BankRandomForestRegression\").getOrCreate()\n",
        "\n",
        "# 2. Load dataset\n",
        "filename = \"bank-full.csv\"\n",
        "data = spark.read.csv(filename, header=True, inferSchema=True, sep=';')\n",
        "data.printSchema()\n",
        "\n",
        "# 3. Define columns based on your schema\n",
        "numeric_cols = ['age', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "target_col = 'balance'\n",
        "\n",
        "# 4. Index + OneHotEncode categorical columns\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid='keep') for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_encoded\") for col in categorical_cols]\n",
        "\n",
        "# 5. Assemble features\n",
        "assembler_inputs = numeric_cols + [f\"{col}_encoded\" for col in categorical_cols]\n",
        "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "# 6. Build full pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "# 7. Transform dataset\n",
        "pipeline_model = pipeline.fit(data)\n",
        "processed_data = pipeline_model.transform(data).select(target_col, \"features\")\n",
        "\n",
        "# 8. Train/test split\n",
        "train_data, test_data = processed_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 9. Train Random Forest Regressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=target_col, numTrees=100, maxDepth=10)\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "# 10. Predict\n",
        "predictions = rf_model.transform(test_data)\n",
        "\n",
        "# 11. Evaluate performance\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse = evaluator_rmse.evaluate(predictions)\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "print(\"\\nðŸŒ² Random Forest Performance:\")\n",
        "print(f\"âœ… RMSE: {rmse:.2f}\")\n",
        "print(f\"âœ… RÂ²: {r2:.4f}\")\n",
        "\n",
        "# 12. Show predictions\n",
        "predictions.select(target_col, \"prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5l_qfiFqPj8",
        "outputId": "db95e7a2-4ddc-4377-f23b-c94902c1124a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- y: string (nullable = true)\n",
            "\n",
            "\n",
            "ðŸŒ² Random Forest Performance:\n",
            "âœ… RMSE: 2812.73\n",
            "âœ… RÂ²: 0.0396\n",
            "+-------+------------------+\n",
            "|balance|        prediction|\n",
            "+-------+------------------+\n",
            "|  -4057| 2267.919843746184|\n",
            "|  -2827|-218.8666096320837|\n",
            "|  -2604|1232.9160974044155|\n",
            "|  -2049|1660.6567709733022|\n",
            "|  -1884|1273.2068800267814|\n",
            "+-------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "# 1. Start Spark session\n",
        "spark = SparkSession.builder.appName(\"BankYClassifier\").getOrCreate()\n",
        "\n",
        "# 2. Load dataset\n",
        "filename = \"bank-full.csv\"\n",
        "data = spark.read.csv(filename, header=True, inferSchema=True, sep=';')\n",
        "\n",
        "# 3. Define columns\n",
        "numeric_cols = ['age', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "label_col = 'y'\n",
        "\n",
        "# 4. Index label column\n",
        "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\", handleInvalid='keep')\n",
        "\n",
        "# 5. Index and encode categorical columns\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid='keep') for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_encoded\") for col in categorical_cols]\n",
        "\n",
        "# 6. Assemble all features\n",
        "assembler_inputs = numeric_cols + [f\"{col}_encoded\" for col in categorical_cols]\n",
        "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "# 7. Build the pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer] + indexers + encoders + [assembler])\n",
        "\n",
        "# 8. Transform the data\n",
        "pipeline_model = pipeline.fit(data)\n",
        "processed_data = pipeline_model.transform(data).select(\"label\", \"features\")\n",
        "\n",
        "# 9. Split into train/test\n",
        "train_data, test_data = processed_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 10. Train Random Forest Classifier\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100, maxDepth=10)\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "# 11. Make predictions\n",
        "predictions = rf_model.transform(test_data)\n",
        "\n",
        "# 12. Evaluate model\n",
        "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "f1 = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "print(f\"\\nðŸŒ² Random Forest Classification Performance:\")\n",
        "print(f\"âœ… Accuracy: {accuracy:.4f}\")\n",
        "print(f\"âœ… F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 13. Show sample predictions\n",
        "predictions.select(\"label\", \"prediction\", \"probability\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEYvDK7AqzN7",
        "outputId": "876fd768-3ecb-4b09-99fe-8adb4572f1c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŒ² Random Forest Classification Performance:\n",
            "âœ… Accuracy: 0.9000\n",
            "âœ… F1 Score: 0.8760\n",
            "+-----+----------+--------------------+\n",
            "|label|prediction|         probability|\n",
            "+-----+----------+--------------------+\n",
            "|  0.0|       0.0|[0.96666177920040...|\n",
            "|  0.0|       0.0|[0.92786810145475...|\n",
            "|  0.0|       0.0|[0.96686278228263...|\n",
            "|  0.0|       0.0|[0.96709225131151...|\n",
            "|  0.0|       0.0|[0.96794829091001...|\n",
            "+-----+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}