{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrJNJSkkU5IZ5OapQK8wnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/colab-notebooks/blob/main/Colab_Pyspark_Utility_Functions_and_Visualizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HazlZ5np-C4x",
        "outputId": "79392842-2ba7-4e41-bfba-e8ca1262dff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "--2025-06-12 13:39:00--  https://raw.githubusercontent.com/Apress/applied-data-science-using-pyspark/refs/heads/main/Ch02/Chapter2_Data/movie_data_part1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29227553 (28M) [text/plain]\n",
            "Saving to: ‘movies.csv’\n",
            "\n",
            "movies.csv          100%[===================>]  27.87M   182MB/s    in 0.2s    \n",
            "\n",
            "2025-06-12 13:39:01 (182 MB/s) - ‘movies.csv’ saved [29227553/29227553]\n",
            "\n",
            "+---------------------+------+-----+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+-------+-------+--------+--------------------+--------------------+------------+\n",
            "|belongs_to_collection|budget|   id|original_language|      original_title|            overview|popularity|production_companies|production_countries|release_date|revenue|runtime|  status|             tagline|               title|vote_average|\n",
            "+---------------------+------+-----+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+-------+-------+--------+--------------------+--------------------+------------+\n",
            "|                 NULL|     0|43000|               fr|  Le Caporal épinglé|The story serves ...|     2.503|[{'id': 16059, 'l...|[{'iso_3166_1': '...|  1962-05-23|      0|     90|Released|                NULL|The Elusive Corporal|         5.9|\n",
            "|                 NULL|     0|43001|               fr|Cybèle ou les dim...|The tragic story ...|      5.51|[{'id': 7808, 'lo...|[{'iso_3166_1': '...|  1962-11-12|      0|    110|Released|                NULL|  Sundays and Cybele|         7.4|\n",
            "|                 NULL|     0|43002|               en|Lonely Are the Brave|A fiercely indepe...|      5.62|[{'id': 3810, 'lo...|[{'iso_3166_1': '...|  1962-05-24|      0|    107|Released|Life can never ca...|Lonely Are the Brave|         7.5|\n",
            "|                 NULL|     0|43003|               fr|Vérités et Mensonges|Documents the liv...|     7.159|[{'id': 36547, 'l...|[{'iso_3166_1': '...|  1975-03-12|      0|     89|Released|                NULL|          F for Fake|         7.5|\n",
            "|                 NULL|500000|43004|               en|Long Day's Journe...|The film follows ...|     3.988|[{'id': 77598, 'l...|[{'iso_3166_1': '...|  1962-10-09|      0|    174|Released|PRIDE...POWER...P...|Long Day's Journe...|         6.8|\n",
            "|                 NULL|     0|43006|               en|           My Geisha|\"A director's (Yv...|     3.194|[{'id': 82939, 'l...|[{'iso_3166_1': '...|  1962-03-09|      0|    119|Released|                NULL|           My Geisha|         6.1|\n",
            "|                 NULL|     0|43007|               en|Period of Adjustment|George Haverstick...|     2.689|[{'id': 13359, 'l...|[{'iso_3166_1': '...|  1962-10-31|      0|    112|Released|The agonizing pau...|Period of Adjustment|         6.4|\n",
            "|                 NULL|     0|43008|               en|    The Hanging Tree|Character study o...|     6.537|[{'id': 14248, 'l...|[{'iso_3166_1': '...|  1959-03-13|      0|    107|Released|From The Prize No...|    The Hanging Tree|         6.6|\n",
            "|                 NULL|     0|43010|               de|Sherlock Holmes u...|Sherlock Holmes a...|     4.297|[{'id': 1787, 'lo...|[{'iso_3166_1': '...|  1962-01-01|      0|     87|Released|                NULL|Sherlock Holmes a...|         5.5|\n",
            "|                 NULL|     0|43011|               en|  Sodom and Gomorrah|Sex, torture and ...|     4.417|[{'id': 8894, 'lo...|[{'iso_3166_1': '...|  1962-01-01|      0|    154|Released|The cities that m...|  Sodom and Gomorrah|         5.4|\n",
            "+---------------------+------+-----+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+-------+-------+--------+--------------------+--------------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install pyspark\n",
        "!pip install pyspark\n",
        "\n",
        "# initiate pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "# download sample\n",
        "!wget -O movies.csv \"https://raw.githubusercontent.com/Apress/applied-data-science-using-pyspark/refs/heads/main/Ch02/Chapter2_Data/movie_data_part1.csv\"\n",
        "df = spark.read.csv(\"movies.csv\", header=True, sep='|', inferSchema=False)\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Casting Multiple Columns\n",
        "\n",
        "#Importing necessary libraries\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "#Identifying and assigning lists of variables\n",
        "int_vars=['id']\n",
        "float_vars=['budget', 'popularity', 'revenue']\n",
        "date_vars=['release_date']\n",
        "\n",
        "#Converting integer variables\n",
        "for column in int_vars:\n",
        "  df = df.withColumn(column,df[column].cast(IntegerType()))\n",
        "\n",
        "# Converting float variables\n",
        "for column in float_vars:\n",
        "  df=df.withColumn(column,df[column].cast(FloatType()))\n",
        "\n",
        "# Converting float variables\n",
        "for column in date_vars:\n",
        "  df=df.withColumn(column,df[column].cast(DateType()))\n",
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7BM0P10A5k0",
        "outputId": "c3e6149e-686e-44b4-8226-cb99f70239f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('belongs_to_collection', 'string'),\n",
              " ('budget', 'float'),\n",
              " ('id', 'int'),\n",
              " ('original_language', 'string'),\n",
              " ('original_title', 'string'),\n",
              " ('overview', 'string'),\n",
              " ('popularity', 'float'),\n",
              " ('production_companies', 'string'),\n",
              " ('production_countries', 'string'),\n",
              " ('release_date', 'date'),\n",
              " ('revenue', 'float'),\n",
              " ('runtime', 'string'),\n",
              " ('status', 'string'),\n",
              " ('tagline', 'string'),\n",
              " ('title', 'string'),\n",
              " ('vote_average', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using when function\n",
        "df_with_newcols = df.select('id', 'budget','popularity').\\\n",
        "withColumn('budget_cat', when(df['budget']<10000000,'Small').when(df['budget']<100000000,'Medium').otherwise('Big')).\\\n",
        "withColumn('ratings', when(df['popularity']<3,'Low').\n",
        "when(df['popularity']<5,'Mid').otherwise('High'))\n",
        "\n",
        "df_with_newcols.show(15, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Add-SjH-iXH",
        "outputId": "8e549185-482a-44c0-8fe6-c04fa70342dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+----------+----------+-------+\n",
            "|id   |budget   |popularity|budget_cat|ratings|\n",
            "+-----+---------+----------+----------+-------+\n",
            "|43000|0.0      |2.503     |Small     |Low    |\n",
            "|43001|0.0      |5.51      |Small     |High   |\n",
            "|43002|0.0      |5.62      |Small     |High   |\n",
            "|43003|0.0      |7.159     |Small     |High   |\n",
            "|43004|500000.0 |3.988     |Small     |Mid    |\n",
            "|43006|0.0      |3.194     |Small     |Mid    |\n",
            "|43007|0.0      |2.689     |Small     |Low    |\n",
            "|43008|0.0      |6.537     |Small     |High   |\n",
            "|43010|0.0      |4.297     |Small     |Mid    |\n",
            "|43011|0.0      |4.417     |Small     |Mid    |\n",
            "|43012|7000000.0|4.722     |Small     |Mid    |\n",
            "|43013|0.0      |2.543     |Small     |Low    |\n",
            "|43014|0.0      |4.303     |Small     |Mid    |\n",
            "|43015|0.0      |3.493     |Small     |Mid    |\n",
            "|43016|0.0      |2.851     |Small     |Low    |\n",
            "+-----+---------+----------+----------+-------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating two variables\n",
        "df_with_newcols = df_with_newcols.withColumn('BudgetRating_Category',concat(df_with_newcols.budget_cat,df_with_newcols.ratings))\n",
        "\n",
        "# Changing the new variable to lowercase\n",
        "df_with_newcols = df_with_newcols.withColumn('BudgetRating_Category',trim(lower(df_with_newcols.BudgetRating_Category)))\n",
        "df_with_newcols.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTjc41ctCCRe",
        "outputId": "b05a07e7-4dea-4f8a-f1d0-f246278fa089"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+----------+----------+-------+---------------------+\n",
            "|   id|   budget|popularity|budget_cat|ratings|BudgetRating_Category|\n",
            "+-----+---------+----------+----------+-------+---------------------+\n",
            "|43000|      0.0|     2.503|     Small|    Low|             smalllow|\n",
            "|43001|      0.0|      5.51|     Small|   High|            smallhigh|\n",
            "|43002|      0.0|      5.62|     Small|   High|            smallhigh|\n",
            "|43003|      0.0|     7.159|     Small|   High|            smallhigh|\n",
            "|43004| 500000.0|     3.988|     Small|    Mid|             smallmid|\n",
            "|43006|      0.0|     3.194|     Small|    Mid|             smallmid|\n",
            "|43007|      0.0|     2.689|     Small|    Low|             smalllow|\n",
            "|43008|      0.0|     6.537|     Small|   High|            smallhigh|\n",
            "|43010|      0.0|     4.297|     Small|    Mid|             smallmid|\n",
            "|43011|      0.0|     4.417|     Small|    Mid|             smallmid|\n",
            "|43012|7000000.0|     4.722|     Small|    Mid|             smallmid|\n",
            "|43013|      0.0|     2.543|     Small|    Low|             smalllow|\n",
            "|43014|      0.0|     4.303|     Small|    Mid|             smallmid|\n",
            "|43015|      0.0|     3.493|     Small|    Mid|             smallmid|\n",
            "|43016|      0.0|     2.851|     Small|    Low|             smalllow|\n",
            "|43017|      0.0|     4.047|     Small|    Mid|             smallmid|\n",
            "|43018|      0.0|     2.661|     Small|    Low|             smalllow|\n",
            "|43019|      0.0|     3.225|     Small|    Mid|             smallmid|\n",
            "|43020|      0.0|      5.72|     Small|   High|            smallhigh|\n",
            "|43021|      0.0|     3.292|     Small|    Mid|             smallmid|\n",
            "+-----+---------+----------+----------+-------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Registering Dataframes\n",
        "\n",
        "# Registering temporary table\n",
        "df_with_newcols.registerTempTable('temp_data')\n",
        "\n",
        "# Applying the function to show the results\n",
        "spark.sql('select ratings, count(ratings) from temp_data group by ratings').show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGXLGjhsCe8L",
        "outputId": "45b19392-2d7a-431b-b0c1-0d743a4f3fed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+\n",
            "|ratings|count(ratings)|\n",
            "+-------+--------------+\n",
            "|High   |16856         |\n",
            "|Low    |14865         |\n",
            "|Mid    |12277         |\n",
            "+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Window Functions\n",
        "\n",
        "# Importing the window functions\n",
        "from pyspark.sql.window import *\n",
        "\n",
        "# Step 1: Filtering the missing values\n",
        "df_with_newcols=df_with_newcols.filter( (df_with_newcols['popularity'].isNotNull()) & (~isnan(df_with_newcols['popularity'])) )\n",
        "\n",
        "# Step 2: Applying the window functions for calculating deciles\n",
        "df_with_newcols = df_with_newcols.select(\"id\",\"budget\",\"popularity\", ntile(10).over(Window.partitionBy().orderBy(df_with_newcols['popularity'].desc())).alias(\"decile_rank\"))\n",
        "\n",
        "# Step 3:Dispalying the values\n",
        "df_with_newcols.groupby(\"decile_rank\").agg(min('popularity').alias('min_popularity'),max('popularity').alias('max_popularity'),count('popularity')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr0Ox48wEmWK",
        "outputId": "a29e866c-051c-452e-d212-7e668404d1f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+--------------+-----------------+\n",
            "|decile_rank|min_popularity|max_popularity|count(popularity)|\n",
            "+-----------+--------------+--------------+-----------------+\n",
            "|          1|        10.185|         180.0|             4379|\n",
            "|          2|         7.481|        10.182|             4379|\n",
            "|          3|         5.841|         7.481|             4379|\n",
            "|          4|         4.823|         5.841|             4378|\n",
            "|          5|         4.054|         4.822|             4378|\n",
            "|          6|         3.383|         4.054|             4378|\n",
            "|          7|         2.747|         3.383|             4378|\n",
            "|          8|         2.075|         2.747|             4378|\n",
            "|          9|         1.389|         2.075|             4378|\n",
            "|         10|           0.6|         1.389|             4378|\n",
            "+-----------+--------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FInd the second most popular movie in the year 1970\n",
        "\n",
        "# Step 1: Import the window functions\n",
        "from pyspark.sql.window import *\n",
        "\n",
        "# Step 2: Select the required subset of columns\n",
        "df_second_best = df.select('id', 'popularity', 'release_date')\n",
        "\n",
        "# Step 3: Create the year column from release date\n",
        "df_second_best = df_second_best.withColumn('release_year',year('release_date')).drop('release_date')\n",
        "\n",
        "# Step 4: Define partition function\n",
        "year_window = Window.partitionBy(df_second_best['release_year']).orderBy(df_with_newcols['popularity'].desc())\n",
        "\n",
        "# Step 5: Apply partition function\n",
        "df_second_best = df_second_best.select('id', 'popularity', 'release_year',rank().over(year_window).alias(\"rank\"))\n",
        "\n",
        "# Step 6: Find the second best rating for the year 1970\n",
        "df_second_best.filter((df_second_best['release_year'] == 1970) & (df_second_best['rank']==2)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkiT9T4wGce1",
        "outputId": "c6b8126e-023c-447d-800d-8f7e9e02eb0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------------+----+\n",
            "|   id|popularity|release_year|rank|\n",
            "+-----+----------+------------+----+\n",
            "|11202|    14.029|        1970|   2|\n",
            "+-----+----------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title what is the difference between the revenue of the highest-grossing film of the year and other films within that year?\n",
        "\n",
        "from pyspark.sql.functions import col, to_date, year, max\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Convert release_date and extract year\n",
        "df_revenue = df.select(\n",
        "    'id',\n",
        "    'revenue',\n",
        "    to_date('release_date', 'yyyy-MM-dd').alias('release_date')\n",
        ").withColumn('release_year', year('release_date'))\n",
        "\n",
        "# Filter out rows with nulls in critical columns\n",
        "df_revenue = df_revenue.filter(col('id').isNotNull() & col('revenue').isNotNull() & col('release_year').isNotNull())\n",
        "\n",
        "# Define window\n",
        "windowRev = Window.partitionBy('release_year')\\\n",
        "                  .orderBy(col('revenue').desc())\\\n",
        "                  .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
        "\n",
        "# Add revenue difference\n",
        "df_revenue = df_revenue.withColumn(\n",
        "    'revenue_difference',\n",
        "    max(col('revenue')).over(windowRev) - col('revenue')\n",
        ")\n",
        "\n",
        "# Show final result\n",
        "df_revenue.select('id', 'revenue', 'release_year', 'revenue_difference').show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xZf7UXVHBWE",
        "outputId": "3c70dad3-7a42-4432-f2f7-7e53ab75ae96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+------------+------------------+\n",
            "|id   |revenue  |release_year|revenue_difference|\n",
            "+-----+---------+------------+------------------+\n",
            "|70512|0.0      |1911        |0.0               |\n",
            "|46751|0.0      |1911        |0.0               |\n",
            "|96128|1800000.0|1913        |0.0               |\n",
            "|28627|0.0      |1913        |1800000.0         |\n",
            "|56511|0.0      |1913        |1800000.0         |\n",
            "|56516|0.0      |1913        |1800000.0         |\n",
            "|98078|0.0      |1914        |0.0               |\n",
            "|28196|0.0      |1914        |0.0               |\n",
            "|5153 |0.0      |1914        |0.0               |\n",
            "|22943|0.0      |1914        |0.0               |\n",
            "+-----+---------+------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_date, year, max\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Convert release_date and extract year\n",
        "df_revenue = df.select(\n",
        "    'id',\n",
        "    'revenue',\n",
        "    to_date('release_date', 'yyyy-MM-dd').alias('release_date')\n",
        ").withColumn('release_year', year('release_date'))\n",
        "\n",
        "# Filter out rows with nulls in critical columns\n",
        "df_revenue = df_revenue.filter(col('id').isNotNull() & col('revenue').isNotNull() & col('release_year').isNotNull())\n",
        "\n",
        "# Define window\n",
        "windowRev = Window.partitionBy('release_year')\\\n",
        "                  .orderBy(col('revenue').desc())\\\n",
        "                  .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
        "\n",
        "# Add revenue difference\n",
        "df_revenue = df_revenue.withColumn(\n",
        "    'revenue_difference',\n",
        "    max(col('revenue')).over(windowRev) - col('revenue')\n",
        ")\n",
        "\n",
        "# Show final result\n",
        "df_revenue.select('id', 'revenue', 'release_year', 'revenue_difference').show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el46j8NYOVuH",
        "outputId": "81c7dd6d-1e25-43d1-fe85-0ee1df3337d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+------------+------------------+\n",
            "|id   |revenue  |release_year|revenue_difference|\n",
            "+-----+---------+------------+------------------+\n",
            "|70512|0.0      |1911        |0.0               |\n",
            "|46751|0.0      |1911        |0.0               |\n",
            "|96128|1800000.0|1913        |0.0               |\n",
            "|28627|0.0      |1913        |1800000.0         |\n",
            "|56511|0.0      |1913        |1800000.0         |\n",
            "|56516|0.0      |1913        |1800000.0         |\n",
            "|98078|0.0      |1914        |0.0               |\n",
            "|28196|0.0      |1914        |0.0               |\n",
            "|5153 |0.0      |1914        |0.0               |\n",
            "|22943|0.0      |1914        |0.0               |\n",
            "+-----+---------+------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Collect List\n",
        "\n",
        "# Step 1: Create the year column from release date\n",
        "df = df.withColumn('release_year',year('release_date'))\n",
        "\n",
        "# Step 2: Apply collect_list function to gather all occurrences\n",
        "df.filter(\"title=='The Lost World'\").groupby('title').agg(collect_list(\"release_year\")).show(1,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz11DVRMQfWj",
        "outputId": "a33d1b46-8235-4054-c5d8-3acb6241760c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------------------------+\n",
            "|title         |collect_list(release_year)          |\n",
            "+--------------+------------------------------------+\n",
            "|The Lost World|[1999, 2001, 1925, 1960, 1992, 1998]|\n",
            "+--------------+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "(df\n",
        "    # 1️⃣  Filter first – touch as few rows as possible\n",
        "    .where(F.col(\"title\") == \"The Lost World\")\n",
        "\n",
        "    # 2️⃣  Project only the two columns you still need\n",
        "    .select(\n",
        "        \"title\",\n",
        "        F.year(\"release_date\").alias(\"release_year\")   # compute year on-the-fly\n",
        "    )\n",
        "\n",
        "    # 3️⃣  Single shuffle: group → collect_list\n",
        "    .groupBy(\"title\")\n",
        "    .agg(\n",
        "        F.sort_array(            # optional: deterministic order\n",
        "            F.collect_list(\"release_year\")\n",
        "        ).alias(\"release_years\")\n",
        "    )\n",
        "    .show(1, False)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXtTJ7E7Q2qT",
        "outputId": "0a4dc397-fddd-4de0-c5e3-c311ee5bd387"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------------------------+\n",
            "|title         |release_years                       |\n",
            "+--------------+------------------------------------+\n",
            "|The Lost World|[1925, 1960, 1992, 1998, 1999, 2001]|\n",
            "+--------------+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache if reused\n",
        "sub = df.where(F.col(\"title\") == \"The Lost World\").select(\"title\", F.year(\"release_date\").alias(\"release_year\"))\n",
        "sub.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaCuRdfvRDaB",
        "outputId": "3515cdd2-c9ab-443f-dd65-adbefc084ce9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[title: string, release_year: int]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repartition on the grouping key\n",
        "sub = sub.repartition(\"title\")"
      ],
      "metadata": {
        "id": "L5uFAwq0RIuI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sampling\n",
        "\n",
        "# Simple random sampling in PySpark without replacement\n",
        "df_sample = df.sample(False, 0.4, seed=11)\n",
        "print(f\"Sample size: {df_sample.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z79Wjz-gRP5L",
        "outputId": "1c811560-090f-4c72-bc80-06266b56ae56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample size: 17627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple random sampling in PySpark with replacement\n",
        "df_sample = df.sample(True, 0.4, 11)\n",
        "df_sample.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHy8Zwq_XjMX",
        "outputId": "66571d46-2b79-4258-9e1e-8451432a9f8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17645"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified sampling in PySpark\n",
        "df_strat = df.sampleBy(\"release_year\", fractions={1959: 0.2, 1960: 0.4,1961: 0.4}, seed=11)\n",
        "df_strat.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0kQf2yJXmxs",
        "outputId": "66a374f1-28a1-4dce-c468-caf447c9e31f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the output\n",
        "df.write.format('csv').option('delimiter', '|').save('output_df')"
      ],
      "metadata": {
        "id": "Xc2TGZMhZGjm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving from multiple cluster\n",
        "df.coalesce(1).write.format('csv').option('delimiter', '|').save('output_coalesced_df')"
      ],
      "metadata": {
        "id": "lrxbx-udZgNj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving with partition\n",
        "df.write.partitionBy('release_year').format('csv').option('delimiter', '|').save('output_df_partitioned')"
      ],
      "metadata": {
        "id": "Lz1lZ_mcZwcK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving to hive table\n",
        "df.write.saveAsTable('film_ratings')"
      ],
      "metadata": {
        "id": "1UQoNZOgZ6pF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving to pandas dataframe\n",
        "\n",
        "# Pandas to PySpark\n",
        "df_pandas=df.toPandas()\n",
        "\n",
        "# Pandas to PySpark\n",
        "df_py = spark.createDataFrame(df_pandas)"
      ],
      "metadata": {
        "id": "FzFvKPzkaOhJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Joins\n",
        "\n",
        "# Step 1: Download the ZIP file\n",
        "!wget -O movie_data.zip \"https://github.com/Apress/applied-data-science-using-pyspark/raw/refs/heads/main/Ch02/Chapter2_Data/movie_data_part2_v1.csv.zip\"\n",
        "\n",
        "# Step 2: Unzip the file\n",
        "!unzip -o movie_data.zip\n",
        "\n",
        "# Step 3: Rename the extracted CSV file\n",
        "!mv \"movie_data_part2_v1.csv\" \"movie_data2.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CODoYAieOF9",
        "outputId": "88a43879-c3e6-4b5a-c81a-ec3d9cf6fea4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-12 14:16:33--  https://github.com/Apress/applied-data-science-using-pyspark/raw/refs/heads/main/Ch02/Chapter2_Data/movie_data_part2_v1.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Apress/applied-data-science-using-pyspark/refs/heads/main/Ch02/Chapter2_Data/movie_data_part2_v1.csv.zip [following]\n",
            "--2025-06-12 14:16:33--  https://raw.githubusercontent.com/Apress/applied-data-science-using-pyspark/refs/heads/main/Ch02/Chapter2_Data/movie_data_part2_v1.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21172903 (20M) [application/zip]\n",
            "Saving to: ‘movie_data.zip’\n",
            "\n",
            "movie_data.zip      100%[===================>]  20.19M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-06-12 14:16:33 (146 MB/s) - ‘movie_data.zip’ saved [21172903/21172903]\n",
            "\n",
            "Archive:  movie_data.zip\n",
            "  inflating: movie_data_part2_v1.csv  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._movie_data_part2_v1.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input parameters\n",
        "file_location = \"movie_data2.csv\"\n",
        "file_type = \"csv\"\n",
        "infer_schema = \"False\"\n",
        "first_row_is_header = \"True\"\n",
        "delimiter = \"|\"\n",
        "\n",
        "# Bring all the options together to read the csv file\n",
        "df_p1 = spark.read.format(file_type) \\\n",
        ".option(\"inferSchema\", infer_schema) \\\n",
        ".option(\"header\", first_row_is_header) \\\n",
        ".option(\"sep\", delimiter) \\\n",
        ".load(file_location)\n",
        "\n",
        "# Cast identifer into the right datatype\n",
        "df_p1 = df_p1.withColumn('id',df_p1['id'].cast(\"integer\"))\n",
        "\n",
        "# Filter missing values\n",
        "df_p1 = df_p1.filter((df_p1['id'].isNotNull()) & (~isnan(df_p1['id'])))"
      ],
      "metadata": {
        "id": "NxsMgjoDgEL9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner join\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'inner').printSchema()\n",
        "df.join(df_p1, df['id'] == df_p1['id']).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIXsLDK0hXLB",
        "outputId": "ece30417-c249-4f9a-bcd0-aaf3f9042fa8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: float (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: float (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: date (nullable = true)\n",
            " |-- revenue: float (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- release_year: integer (nullable = true)\n",
            " |-- cast: string (nullable = true)\n",
            " |-- adult: string (nullable = true)\n",
            " |-- directors: string (nullable = true)\n",
            " |-- vote_count: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- poster_path: string (nullable = true)\n",
            " |-- homepage: string (nullable = true)\n",
            " |-- imdb_id: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- video: string (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24998"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left Join\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'left').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr6TYSgRhe71",
        "outputId": "f6b81a04-d6dc-4da0-f2ad-90333d60819a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43998"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Right Join\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'right').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wZPQcWUhrfe",
        "outputId": "92e76983-c052-400c-d4ac-938a8e50d2d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24998"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.join(df_p1, df['id'] == df_p1['id'],'outer').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gySNC-5xhz94",
        "outputId": "ea8b799e-b470-424d-8bfe-bda55d0b7ce3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43998"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left Anti Join\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'left_anti').printSchema()\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'left_anti').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW3qcTm9h8ir",
        "outputId": "f432a393-ff77-417e-aad5-88ca1ccf4c40"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: float (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: float (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: date (nullable = true)\n",
            " |-- revenue: float (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- release_year: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left Semi Join\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'left_semi').printSchema()\n",
        "df.join(df_p1, df['id'] == df_p1['id'],'left_semi').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIyQwGzriCwi",
        "outputId": "1f889d6c-aff4-4c64-d487-65d9296d77e0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: float (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: float (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: date (nullable = true)\n",
            " |-- revenue: float (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- release_year: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24998"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcast Join\n",
        "df.join(broadcast(df_p1), df['id'] == df_p1['id'],'left_semi').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3icHRNZsiJRh",
        "outputId": "bbb4bdf9-4b64-4aa0-9876-c8b1860c4d65"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24998"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}